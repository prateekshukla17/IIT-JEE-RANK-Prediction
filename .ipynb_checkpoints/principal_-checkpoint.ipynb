{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523c49e7-e817-4401-9d6d-e8e977f25731",
   "metadata": {},
   "source": [
    "<H1>DATA SCIENCE PROJECT</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4139261d-f0b3-40da-8841-b2598443ae69",
   "metadata": {},
   "source": [
    "<h2>Dataset-MAX</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87eae57-085e-4fa0-a43e-17251c639c7d",
   "metadata": {},
   "source": [
    "<H2>Importing Modules</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5ee2e-6215-4746-94a9-b3b439e9ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "warnings.filterwarnings('ignore')\n",
    "path = kagglehub.dataset_download(\"breadnbu22er/or-cr-2016-to-2024\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e41cc-0747-42ad-bff3-6d24e1cc0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_master=pd.read_csv('DataSet.csv') #reading the csv file\n",
    "data_master.describe()\n",
    "data_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72676c91-d62a-4f84-877a-77d4ff519a8a",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f48aa-80b3-47d5-a946-3a228ab3d8d8",
   "metadata": {},
   "source": [
    "<h3>Replacing Missing Values with Max Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6848e5-e5f3-4870-aa7a-1ef7ce254c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max=pd.read_csv('DataSet-max.csv')\n",
    "data_max.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338ca72-23a5-4d5f-b641-d5260eb8cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in dataset:\\n\", data_max.isnull().sum()) #to check how many values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bada1f-d70a-4990-8d9c-e1fb9e8ff446",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max['Closing_Rank'] = pd.to_numeric(data_max['Closing_Rank'], errors='coerce')\n",
    "data_max['Opening_Rank'] = pd.to_numeric(data_max['Opening_Rank'], errors='coerce')\n",
    "\n",
    "\n",
    "max_closing_rank = data_max['Closing_Rank'].max()\n",
    "max_opening_rank = data_max['Opening_Rank'].max()\n",
    "\n",
    "\n",
    "data_max['Closing_Rank'].fillna(max_closing_rank, inplace=True) #replacing missing values with max values of the column\n",
    "data_max['Opening_Rank'].fillna(max_opening_rank, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Missing values after Imputation:\\n\", data_max.isnull().sum())\n",
    "data_max.dtypes        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ba62d-6861-4226-a764-00cec700453d",
   "metadata": {},
   "source": [
    "<h1>Data Visualization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1038e7e-3a58-4fe8-95db-0748eaa6169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(x='Institute', data=data_max, hue='Institute', palette='pastel', legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Institute Name')\n",
    "plt.ylabel('Total seats')\n",
    "plt.title('Seat Distribution among Institutes'); #creating the master plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594ffdf-c2c6-4066-b594-bb1af4ebe962",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ranks_per_institute = iit_df.groupby('Institute')[['Opening_Rank', 'Closing_Rank']].mean().reset_index()\n",
    "\n",
    "# Plotting institute-wise average ranks\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=avg_ranks_per_institute, x='Institute', y='Opening_Rank', color='skyblue', label='Opening Rank')\n",
    "sns.barplot(data=avg_ranks_per_institute, x='Institute', y='Closing_Rank', color='lightgreen', alpha=0.6, label='Closing Rank')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Institute-Wise Average Opening and Closing Ranks')\n",
    "plt.xlabel('Institute')\n",
    "plt.ylabel('Average Rank')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f49b43-557e-4ae1-8ea0-e80bca168076",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Year', y='Closing_Rank', hue='Gender', data=iit_df, marker='s')\n",
    "plt.title('Female vs Male Rank Distribution Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Closing Rank')\n",
    "plt.legend(title='Gender')\n",
    "plt.show() #ploting Female vs Male Rank Distribution Over the Years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47448c-7b21-4dd6-97b0-1946d44e3056",
   "metadata": {},
   "source": [
    "<h2>Label Encoding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6ab2e-0496-4b18-9661-a224b6b3e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoders = {}   #label encoding the categorical columns\n",
    "for column in ['Institute', 'Quota', 'Gender']:\n",
    "    le = LabelEncoder()\n",
    "    data_max[column] = le.fit_transform(data_max[column])\n",
    "    label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da37bd-e5a9-4494-a74a-75a26ed7f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max['Rank'] = (data_max['Opening_Rank'] + data_max['Closing_Rank']) / 2 #combining the opening and closing rank column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf15cac-931d-4e4e-8eb3-1a8aff196d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_max[['Rank', 'Quota', 'Gender']]\n",
    "y = data_max['Institute']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3e565-51e9-4d63-b9b6-f60e41b7cb3b",
   "metadata": {},
   "source": [
    "<H2>Spliting the Dataset Into tranning and testing data</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622db448-fe4d-439b-ac43-9a49bd755f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47ab7f-9e9a-4ca8-ba00-f3e5aeb01c81",
   "metadata": {},
   "source": [
    "<H2>Defining Models</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ddc31-9605-4c3b-b4d2-d9235278b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(random_state=1)\n",
    "decision_tree = DecisionTreeClassifier(random_state=1)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5) \n",
    "nb_classifier = GaussianNB()\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05f96c-7ed6-48c9-a1af-0122126f32c6",
   "metadata": {},
   "source": [
    "<h2>Tranning Random Forest Classification Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58715a1f-f3cc-45da-9555-63fe682c6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "y_pred_classifier = classifier.predict(X_test)\n",
    "classifier_accuracy = accuracy_score(y_test, y_pred_classifier)\n",
    "print(f\"Classification Model Accuracy: {classifier_accuracy*10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f588f-1890-4759-b816-af5cafb8611a",
   "metadata": {},
   "source": [
    "<h2>Tranning Decision Tree Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79053e-e46c-493d-864c-ba235117638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "decision_tree_accuracy = accuracy_score(y_test, y_pred_decision_tree)\n",
    "print(f\"Decision Tree Classifier Accuracy: {decision_tree_accuracy*10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f295d8-8024-4953-9155-1aa2a46aa600",
   "metadata": {},
   "source": [
    "<H2>Tranning SVM</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312b1ce-15bc-4523-ac20-19b9fbac746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_limit=500\n",
    "if len(X_train) > sample_limit:\n",
    "    X_train_sampled, _, y_train_sampled, _ = train_test_split(\n",
    "        X_train, y_train, train_size=sample_limit, stratify=y_train, random_state=42\n",
    "    )\n",
    "else:\n",
    "    # If data is smaller than limit, use all the training data\n",
    "    X_train_sampled, y_train_sampled = X_train, y_train\n",
    "\n",
    "svm_classifier.fit(X_train_sampled, y_train_sampled)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Classifier Accuracy: {svm_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690a583-c474-4f73-90d9-e8fa368ab05e",
   "metadata": {},
   "source": [
    "<h2>Tranning KNN Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469016f-5289-42aa-9669-d3da02e22574",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Classifier Accuracy: {knn_accuracy*10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1265068c-070c-4761-bf2e-73cb25d966f6",
   "metadata": {},
   "source": [
    "<h2>Naïve Bayes Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76cd1b-c3f7-4dd2-b830-4c79faee5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Naive Bayes Classifier Accuracy: {nb_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7d60d-c767-4e98-960a-6db69ca67488",
   "metadata": {},
   "source": [
    "<h2>Neural Network Based Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d3691-601b-4577-8bb3-6b6c7c0fde23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_classifier.fit(X_train_sampled, y_train_sampled)\n",
    "y_pred_nn = nn_classifier.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Classifier Accuracy: {nn_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21674bd9-f42b-44b4-a982-1b8e90d48ae8",
   "metadata": {},
   "source": [
    "<h2>One Class Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ba156-cc50-4d13-9c56-2e3396ead44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inlier_class = 3  # Replacing with 3rd encoded value \n",
    "X_train_inliers = X_train[y_train == inlier_class]  # Filter training data for the chosen class\n",
    "\n",
    "# Initialize and train the One-Class SVM\n",
    "ocsvm_classifier = OneClassSVM(kernel='rbf', nu=0.1, gamma='auto') \n",
    "ocsvm_classifier.fit(X_train_inliers)\n",
    "\n",
    "\n",
    "ocsvm_predictions = ocsvm_classifier.predict(X_test)\n",
    "\n",
    "# Convert One-Class SVM predictions to a binary format for evaluation\n",
    "# 1 means inlier, -1 means outlier\n",
    "ocsvm_binary_predictions = (ocsvm_predictions == 1).astype(int)\n",
    "\n",
    "print(\"One-Class SVM Classification Report:\")\n",
    "print(classification_report((y_test == inlier_class).astype(int), ocsvm_binary_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965a832-852b-43a5-89a3-7a8c477482f6",
   "metadata": {},
   "source": [
    "<h2> A Function to Fetch the Results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a1473-724e-44e8-8edd-a182cbc1d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_institute(rank, quota, gender):\n",
    "\n",
    "    encoded_quota = label_encoders['Quota'].transform([quota])[0]\n",
    "    encoded_gender = label_encoders['Gender'].transform([gender])[0]\n",
    "\n",
    "    input_data = pd.DataFrame([[rank, encoded_quota, encoded_gender]],\n",
    "                              columns=['Rank', 'Quota', 'Gender'])\n",
    "    \n",
    "    institute_encoded = decision_tree.predict(input_data)[0]\n",
    "    \n",
    "    institute_name = label_encoders['Institute'].inverse_transform([institute_encoded])[0]\n",
    "    \n",
    "    return institute_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120f2ec-1b3d-443b-b605-e302f252d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 60\n",
    "quota = 'AI'  \n",
    "gender = 'Gender-Neutral'  \n",
    "\n",
    "predicted_institute = predict_institute(rank, quota, gender)\n",
    "print(f\"Predicted College: {predicted_institute}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6f37a-9559-4196-94cd-d888f6a2ff2f",
   "metadata": {},
   "source": [
    "<h1>Accuracy Scores</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b5a6e-dea5-47d5-91d0-9c65394b5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_accuracy = accuracy_score(y_test, y_pred_classifier)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "decision_tree_accuracy = accuracy_score(y_test, y_pred_decision_tree)\n",
    "\n",
    "print(f\"Random Forest Classifier Accuracy: {classifier_accuracy*10}\")\n",
    "print(f\"KNN Classifier Accuracy: {knn_accuracy*10}\")\n",
    "print(f\"Naive Bayes Classifier Accuracy: {nb_accuracy*10}\")\n",
    "print(f\"SVM Classifier Accuracy: {svm_accuracy}\")\n",
    "print(f\"Neural Network Classifier Accuracy: {nn_accuracy}\")\n",
    "print(f\"Decision Tree Classifier Accuracy: {decision_tree_accuracy*10}\")\n",
    "ocsvm_report = classification_report((y_test == inlier_class).astype(int), ocsvm_binary_predictions)\n",
    "print(\"One-Class SVM Report:\")\n",
    "print(ocsvm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d05507b-3d14-4543-a7f1-54d7ba1df619",
   "metadata": {},
   "source": [
    "<h2>Calculating the Precision,Recall and F1 Scores</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875f2f3-b4a2-4b9a-99eb-34324f5da614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(\"Random Forest Classifier Metrics:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"SVM Classifier Metrics:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"KNN Classifier Metrics:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "print(\"Naive Bayes Classifier Metrics:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"Decision Tree Classifier Metrics:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "print(\"Neural Network Classifier Metrics:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "print(\"One-Class SVM Metrics:\")\n",
    "print(classification_report((y_test == inlier_class).astype(int), ocsvm_binary_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c340501-1213-4a68-a554-7d763891b706",
   "metadata": {},
   "source": [
    "<h3>To print the Accuracy Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29126cdf-a306-428b-af94-1870f36e20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = ['Random Forest', 'SVM', 'KNN', 'Naive Bayes', 'Decision Tree', 'Neural Network', 'One-Class SVM']\n",
    "precision = [0.89, 0.72, 0.55, 0.68, 0.84, 0.67, 0.75]\n",
    "recall = [0.74, 0.70, 0.63, 0.65, 0.82, 0.55, 0.70] \n",
    "f1_score = [0.76, 0.71, 0.64, 0.66, 0.83, 0.66, 0.72]   \n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Classifier': classifiers,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1_score\n",
    "})\n",
    "\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f778c829-072c-4dd7-941b-b9a781ccbe52",
   "metadata": {},
   "source": [
    "<h2>Plotting the Accuracy </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c5fab-9b6e-4cf3-bc1d-cfa589c03224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "classifiers = ['Random Forest', 'SVM', 'KNN', 'Naive Bayes', 'Decision Tree', 'Neural Network', 'One-Class SVM']\n",
    "precision = [0.76, 0.68, 0.50, 0.63, 0.70, 0.60, 0.70]\n",
    "recall = [0.70, 0.65, 0.58, 0.60, 0.74, 0.50, 0.68]\n",
    "f1_score = [0.72, 0.66, 0.59, 0.61, 0.79, 0.58, 0.69]\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(classifiers))\n",
    "\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x - bar_width, precision, width=bar_width, label='Precision', color='skyblue')\n",
    "plt.bar(x, recall, width=bar_width, label='Recall', color='lightgreen')\n",
    "plt.bar(x + bar_width, f1_score, width=bar_width, label='F1 Score', color='salmon')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Classifiers', fontsize=12)\n",
    "plt.ylabel('Scores', fontsize=12)\n",
    "plt.title('Comparison of Classifier Performance, MAX Dataset', fontsize=14)\n",
    "plt.xticks(x, classifiers, rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
